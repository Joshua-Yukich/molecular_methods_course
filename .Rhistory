OD_true_rct
#
ATE_true_rct + SG_true_rct + SB_true_rct
# WHY IS THE ATE FOR THE EXACT RCT SIMULATION HERE NOT EXACTLY negative TEN?
# BECASUE THERE IS STILL SOME SELECTION BIAS!
# remind you that the arms of this trial are not perfectly balanced on the confounding factors!
real_data_df %>% group_by(d_rand) %>% summarise(mean_age = mean(age), sd_age = sd(age), prop_male = mean(sex))
# so how do we analyze this data from the RCT?
#lets finish it and calculate the actual results....
# well take our untreated bp noisy data as the first measure.
real_data_df$bp_baseline <- real_data_df$bp
# well take the hypothetical noisy treated value as endline for those who got treatment..
real_data_df$bp_endline[real_data_df$d_rand ==1] <- real_data_df$bp_treated[real_data_df$d_rand ==1]
# and well repeat the noising of the bp untreated for people who did not get treated (e.g. their blood pressure
# doesnt change except for the noise of measurement/day to day fluctuation.
real_data_df$bp_endline[real_data_df$d_rand == 0] <- real_data_df$bp_e[real_data_df$d_rand == 0] +
rnorm(n = length(real_data_df$bp_e[real_data_df$d_rand == 0]), sd = 5)
# then calculate the change in BP for each person.
real_data_df$change <- real_data_df$bp_endline - real_data_df$bp_baseline
# visualize
hist(real_data_df$change)
mean(real_data_df$change)
#notice that the mean change is not -10!
#Why?
# how do we analyze?
# t-test or anova of change... but hey, arent RCTs supposed to take away confounding factors?
# yes so things that are only different because of confounding factors (observed or not) shouldn't matter
# we know that our change in systolic BP is indepedent of all confounding factors because we made it
# always -10.
# but our endline BP is not independent of confounding because it depends on Age and Sex and treatment status.
# but because we randomized we can look at estimates of ATE even of the confounded measure,
# why? Because age and sex are balanced across arms. We get the right answer whether or not
# we even adjust for these, and no matter if we look at change or bp at endline!
t.test(change ~ d_rand, data = real_data_df)
t.test(bp_endline ~ d_rand, data = real_data_df)
one.way <- aov(change ~ d_rand, data = real_data_df)
summary(one.way)
one.way_2 <- aov(bp_endline ~ d_rand, data = real_data_df)
summary(one.way_2)
ggplot(data = real_data_df, aes(x=factor(d_rand), y = change,
group = factor(d_rand), fill = factor(d_rand))) + geom_boxplot()
ggplot(data = real_data_df, aes(x=factor(d_rand), y = bp_endline,
group = factor(d_rand), fill = factor(d_rand))) + geom_boxplot()
ggplot(data = real_data_df, aes(x=bp_endline, group=factor(d_rand), fill=factor(d_rand))) + geom_histogram()
ggplot(data = real_data_df, aes(x=change, group=factor(d_rand), fill=factor(d_rand))) + geom_histogram()
# OR REGRESSION....
m1 <- lm(change ~ d_rand, data = real_data_df)
summary(m1)
m2 <- lm(bp_endline ~ d_rand, data = real_data_df)
summary(m2)
m3 <- lm(change ~ d_rand + age + sex, data = real_data_df)
summary(m3)
m4 <- lm(bp_endline ~ d_rand + age + sex, data = real_data_df)
summary(m4)
m5 <- lm(bp_endline ~ d_rand + age + sex + bp_baseline, data = real_data_df)
summary(m5)
m6 <- lm(change ~ d_rand + age + sex + bp_baseline, data = real_data_df)
summary(m6)
plot(cars)
plot(cars)
library(tidyverse)
N <- 100000 # this will be our sample size.
# since w is 'exogenous' we can set it separately.
w <- rnorm(N)
# lets write a simple linear equation for x (with a little noise)
# remember from diagram that X is (associated/predicted/caused) only by W.
# But Y is (associated/predicted/caused) by both W and X so we have to do X first.
# lets say that X is equal to half of W....
x <- .5 * w + rnorm(N)
# take a quick peak at x and w.
plot(x, w)
# now lets calculate y
# here we need the x and w values   y is equal to 0.3 * w and 0.4 * x
# and also there is still some noise
y <- .3 * w + .4 * x + rnorm(N)
# now look at x vs. y and w vs y
plot(x,y)
plot(w,y)
# often they tell you that a con-founder is something associated with the outcome and also another variable,
# but is not on the causal path...
cov(w,y)
cov(w,x)
# first look without adjusting for the confounder.
summary(lm(y ~ x))
# interestingly, you see that the regression coefficient of X is not
# that much like the value that is it supposed to be (0.4) which is the 'truth'
# because we generated the data (Also note that this is an upward bias because W
# has a positive effect on both x and Y which we have ignored (or rather made to depend only on X))
# so adjust for the confounding by W in the next regression.
summary(lm(y ~ x + w))
# this is a much more accurate estimate.
library(AER)
library(ivreg)
samp_size <- 1000
# half to treatment condition, half to control
data_df <- data.frame(treated = c(rep(1, times = samp_size / 2 ), rep(0, times = samp_size / 2 )))
# assign a random confounding variable
data_df$sex <- rbinom(size = 1, n = samp_size, prob = 0.5)
data_df$taker <- ifelse(data_df$sex == 1,
rbinom(n = sum(data_df$sex), size = 1, p = 0.75),
rbinom(n = length(data_df$sex) - sum(data_df$sex), size = 1, 0.15))
data_df$exposed <- ifelse(data_df$treated == 1, rbinom(n = samp_size, size = 1, ifelse(data_df$taker == 1, 0.75, 0.25)), 0)
#make outcome dependent on program exposure and sex per the causal graph discussed. Include noise (other unobserved variation)
data_df$outcomes <- 2*data_df$exposed + 5*data_df$sex + 0.5 + rnorm(n = samp_size, sd = 1)
mean(data_df$outcomes)
t.test(formula = outcomes ~ treated, data = data_df)
summary(lm(formula = outcomes ~ treated, data = data_df))
summary(lm(formula = outcomes ~ treated + sex, data = data_df))
# what if it was observational ----
t.test(formula = outcomes ~ exposed, data = data_df)
summary(lm(formula = outcomes ~ exposed, data = data_df))
summary(lm(formula = outcomes ~ exposed + sex, data = data_df))
t.test(formula = outcomes ~ exposed, data = data_df)
summary(lm(formula = outcomes ~ exposed + taker, data = data_df))
first_stage <- lm(exposed ~ treated, data = data_df)
summary(first_stage)
# how do you get the predictions?
str(first_stage)
#you could just write it out.
predictions <- data_df$treated * 0.5080 + 1.180e-14
predictions
# or rely on the stored coefficients
predictions <- data_df$treated * first_stage$coefficients[2] +first_stage$coefficients[1]
predictions
# or the lm function actually already does this!
first_stage$fitted.values
#Lets add these back into the data-frame to make it easier
data_df$pred_exp <- first_stage$fitted.values
# and summarize them
hist(data_df$pred_exp)
table(data_df$exposed, data_df$pred_exp)
second_stage <- lm(formula = outcomes ~ pred_exp, data = data_df)
summary(second_stage)
samp_size <- 1000
# half to treatment condition, half to control
data_df <- data.frame(treated = c(rep(1, times = samp_size / 2 ), rep(0, times = samp_size / 2 )))
# assign a random confounding variable
data_df$sex <- rbinom(size = 1, n = samp_size, prob = 0.5)
data_df$taker <- ifelse(data_df$sex == 1,
rbinom(n = sum(data_df$sex), size = 1, p = 0.75),
rbinom(n = length(data_df$sex) - sum(data_df$sex), size = 1, 0.15))
data_df$exposed <- ifelse(data_df$treated == 1, rbinom(n = samp_size, size = 1, ifelse(data_df$taker == 1, 0.75, 0.25)), 0)
#make outcome dependent on program exposure and sex per the causal graph discussed. Include noise (other unobserved variation)
data_df$outcomes <- 2*data_df$exposed + 5*data_df$sex + 0.5 + rnorm(n = samp_size, sd = 1)
mean(data_df$outcomes)
mean(data_df$outcomes)
t.test(formula = outcomes ~ treated, data = data_df)
summary(lm(formula = outcomes ~ treated, data = data_df))
summary(lm(formula = outcomes ~ treated + sex, data = data_df))
# what if it was observational ----
t.test(formula = outcomes ~ exposed, data = data_df)
summary(lm(formula = outcomes ~ exposed, data = data_df))
summary(lm(formula = outcomes ~ exposed + sex, data = data_df))
summary(lm(formula = outcomes ~ treated, data = data_df))
summary(lm(formula = outcomes ~ treated + sex, data = data_df))
library(knitr)
library(ggplot2)
data_df <- data.frame("test neg" = c("Type I", "Correct"), "test pos" = c("Correct", "Type II"), row.names = c("True Pos", "True Neg"))
kable(data_df)
x <- seq(0,1, by = 0.01)
y <- sqrt(sqrt(x))
data_df <- data.frame(TPR = x, FPR = y)
ggplot(data_df, aes (x, y)) + geom_line() + theme_minimal() + xlab("FPR (1-Specificity)") + ylab("TPR (Sensitivity)")
two_means <- function(alpha, beta, mu1, mu2, sd) {
2 * (((qnorm((1-(alpha/2))) + qnorm(1-beta)))^2) / ((mu1 - mu2)/sd)^2
}
two_means(alpha = 0.05, beta = 0.2, mu1 = 5, mu2 = 7, sd = 2)
hist(rnorm(n = 10000, mean = 1*10, sd = sqrt(10)))
hist(rpois(n = 10000, lambda = 1*10))
# Counts
# Now you can find a 'canned' formula for this in R in some package somewhere, and in every other stats package... but I'm going to implement it as a function anyway to take the mysterys out of it.
two_counts_simp <- function(lambda1, lambda2) {
4 / (sqrt(lambda1) - sqrt(lambda2))^2
}
two_counts_simp( lambda1 = 30, lambda2 = 36)
alpha <- -0.5
beta_P <- 0.4
outcome_f <- function(P, alpha, beta_P) {
alpha + beta_P * P["P"]  + rnorm(n = 1)
}
outcome_f(alpha = alpha, beta_P = beta_P, P = data.frame(P = 0))
outcome_f(alpha = alpha, beta_P = beta_P,  P = data.frame(P = 1))
hist(unlist(replicate(exp = outcome_f(alpha = alpha, beta_P = beta_P, P = data.frame(P = 0)), n = 1000)))
hist(unlist(replicate(exp = outcome_f(alpha = alpha, beta_P = beta_P, P = data.frame(P = 1)), n = 1000)))
# lets do this into a dataset though....
data_df <- data.frame(P = c(rep(1, times = 1000), rep(0, times = 1000)))
data_df$Y <- apply(X = data_df, MARGIN = 1, FUN = outcome_f, alpha = alpha, beta_P = beta_P)
# plot it
ggplot(data = data_df, aes(x = Y, group = as.factor(P), fill = as.factor(P))) + geom_histogram(position = "dodge")
ggplot(data = data_df, aes(x = as.factor(P), y = Y, group = as.factor(P), fill = as.factor(P))) + geom_boxplot()
summary(lm(data = data_df, formula = Y ~ P))
# set our parameters
set.seed(342)
alpha <- -0.5
beta_P <- 0.1
data_df$Y <- apply(X = data_df, MARGIN = 1, FUN = outcome_f, alpha = alpha, beta_P = beta_P)
# plot it
ggplot(data = data_df, aes(x = Y, group = as.factor(P), fill = as.factor(P))) + geom_histogram(position = "dodge")
ggplot(data = data_df, aes(x = as.factor(P), y = Y, group = as.factor(P), fill = as.factor(P))) + geom_boxplot()
summary(lm(data = data_df, formula = Y ~ P))
nSims <- 10
sample_size <- 2000
power_sims_df <- data.frame(p_val = rep(NA, times = nSims), est_P = rep(NA, times = nSims))
for (i in 1:nSims) {
data_df <- data.frame(P =  c(rep(1, times = sample_size/2), rep(0, times = sample_size/2)))
data_df$Y <- apply(X = data_df, MARGIN = 1, FUN = outcome_f, alpha = alpha, beta_P = beta_P)
power_sims_df[i, "est_P"] <- summary(lm(data = data_df, formula = Y ~ P))$coefficients["P","Estimate"]
power_sims_df[i, "p_val"] <- summary(lm(data = data_df, formula = Y ~ P))$coefficients["P","Pr(>|t|)"]
}
power_sims_df$p_val <= 0.05
sum(power_sims_df$p_val <= 0.05)/ length(power_sims_df$p_val)
# set our parameters
mu <- -0.5 # note that I'm now saying this is the mean of all alphas
alpha_sd <- 1 # we assume that the average of all alphas is zero, but the SD may vary
beta_P <- 0.4
# note here that I'm reworking this function to look at the value of alpha and P in each row.
outcome_f_cluster <- function(X, mu, beta_P) {
mu + X["alpha"] + beta_P * X["P"]  + rnorm(n = 1)
}
data_df <- data.frame(mu = mu, beta_P = beta_P, P = 0, alpha = -0.4)
outcome_f_cluster(X = data_df, mu = mu, beta_P = beta_P)
data_df <- data.frame(mu = mu, beta_P = beta_P, P = 1, alpha = -0.4)
outcome_f_cluster(X = data_df, mu = mu, beta_P = beta_P)
# lets make the whole big data frame
# we need to decide on a couple new things now...
# the number of communities
n_com <- 40
# the number of persons in each community
n_child <- 20
# then lets generate our alphas
alphas <- rnorm(n = n_com, mean = 0 , sd = alpha_sd)
data_df <- data.frame(community = rep(seq(1:n_com), times = n_child), alpha = rep(alphas, times = n_com))
data_df$P <- ifelse(data_df$community <= 10, 1, 0)
# generate some Y's
data_df$Y <- apply(X = data_df, MARGIN = 1, FUN = outcome_f_cluster, mu = -0.5, beta_P = beta_P)
ggplot(data= data_df, aes(x = community, y = Y, group = community)) + geom_boxplot()
ggplot(data= data_df, aes(x = P, y = Y, group = P)) + geom_boxplot()
library(lme4)
library(lmerTest)
summary(lm(data= data_df, formula = Y ~ P))
summary(lmer(data = data_df, formula = Y ~ P + (1|community)))
nSims <- 100
n_com <- 80
n_child <- 20
# set our parameters
mu <- -0.5 # note that I'm now saying this is the mean of all alphas
alpha_sd <- 0.5 # we assume that the average of all alphas is zero, but the SD may vary
beta_P <- 0.4
power_sims_df <- data.frame(p_val = rep(NA, times = nSims), est_P = rep(NA, times = nSims))
for (i in 1:nSims) {
# then lets generate our alphas
alphas <- rnorm(n = n_com, mean = 0 , sd = alpha_sd)
data_df <- data.frame(community = rep(seq(1:n_com), times = n_child), alpha = rep(alphas, times = n_com))
data_df$P <- ifelse(data_df$community <= n_com/2, 1, 0)
# generate some Y's
data_df$Y <- apply(X = data_df, MARGIN = 1, FUN = outcome_f_cluster, mu = -0.5, beta_P = beta_P)
m_res <- summary(lmer(data = data_df, formula = Y ~ P + (1|community)))
power_sims_df[i, "est_P"] <- m_res$coefficients["P","Estimate"]
power_sims_df[i, "p_val"] <- m_res$coefficients["P","Pr(>|t|)"]
}
power_sims_df$p_val <= 0.05
sum(power_sims_df$p_val <= 0.05)/ length(power_sims_df$p_val)
BiocManager::install(version = "3.19")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.19")
#BiocManager::install(version = "3.19")
#install.packages('seqinr')
#install.packages('outbreaker2')
#install.packages('rprojroot')
#install.packages('tidyverse')
#install.packages('ape')
#install.packages('phangorn')
BiocManager::install('DECIPHER')
library(rprojroot)
library(rstudioapi)
library(tidyverse)
library(seqinr)
library(outbreaker2)
library(ape)
library(phangorn)
library(adephylo)
library(adegenet)
library(DECIPHER)
# session info -----
run_date <- date()
run_date
sessionInfo()
# setting working directory and other user preferences -----
if (interactive()) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
base_path <- find_root('base_environment.R')
setwd(base_path)
source('base_environment.R')
# preserve graphics settings ----
par_old <- par()
# load sequence data (in FASTA format)
fas <- "./R_example/sequences_from_session_1.fna"
dna <- readDNAStringSet(fas)
dna # the unaligned sequences
#
DNA <- AlignSeqs(dna)
DNA
# write alignments to file.
writeXStringSet(DNA, file="./R_example/sequences_from_session_1_aligned.fna")
# reload from file (not necessary but worth checking that write worked)
seqs <- read.dna("./R_example/sequences_from_session_1_aligned.fna", format="fasta")
seqs
#create a phyDat object
virus_phyDat <- phyDat(seqs, type = "DNA", levels = NULL)
tree <- NJ(dist.ml(virus_phyDat, "JC"))
# test a vareity of nucleotide substitution models
mt <- modelTest(virus_phyDat, tree = tree, model = c("JC", "F81"))
print(mt)
# choose a model and create a distance matrix
dna_dist <- dist.ml(virus_phyDat, model="JC69")
dna_dist
virus_UPGMA <- upgma(dna_dist)
virus_NJ <- NJ(dna_dist)
#CairoPDF(file = "test.pdf")
plot(virus_UPGMA, main="UPGMA")
#dev.off()
plot(virus_NJ, main = "Neighbor Joining")
plot(virus_NJ, type = "unrooted", cex = 0.5)
plot(virus_NJ, type = "cladogram")
plot(virus_NJ, type = "fan")
plot(virus_NJ, type = "radial")
bullseye(virus_NJ, font = 2, cex = 0.5)
# genome length alignment ----
# load dataset with five 100k+ BP DNA sequences
long_seqs <- readDNAStringSet(file.path(getwd(), "R_example", "plastid_genomes.fa"))
long_seqs
# prep as a local database ----
Seqs2DB(long_seqs, "XStringSet", "long_db", names(long_seqs))
install.packages("RSQLite")\
install.packages("RSQLite")
library(rprojroot)
library(rstudioapi)
library(tidyverse)
library(seqinr)
library(outbreaker2)
library(ape)
library(phangorn)
library(adephylo)
library(adegenet)
library(DECIPHER)
# session info -----
run_date <- date()
run_date
sessionInfo()
# setting working directory and other user preferences -----
if (interactive()) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
###############################################################################
#                                                                             #
#  Intro to Reproducible use of genetic sequences in R and genetic epi        #
#                                                                             #
#   Script developed to highlight reproducible research methods               #
#     and to highlight use of tools related to sequencing and                 #
#     use and interpretation of genetic sequence data in the R                #
#     programming language and environment.                                   #
#                                                                             #
#    Written in R version 4.0.2 using R Studio 1.3.1073                       #
#                                                                             #
#  Dependencies: tidyverse, bioconductor, seqinr, outbreaker2, rprojroot,     #
#               seqinr, ape, phangorn, DECIPHER, adephylo, adegenet           #
#                                                                             #
#                                                                             #
#                   author: Joshua Yukich jyukich@tulane.edu                  #
#                                                                             #
#                                                                             #
#                                                                             #
###############################################################################
# installation of required packages (Commented) ----
#BiocManager::install(version = "3.19")
#install.packages('seqinr')
#install.packages('outbreaker2')
#install.packages('rprojroot')
#install.packages('tidyverse')
#install.packages('ape')
#install.packages('phangorn')
#BiocManager::install('DECIPHER')
#install.packages('adephylo')
#install.packages('adegenet')
# loading required libraries ----
library(rprojroot)
library(rstudioapi)
library(tidyverse)
library(seqinr)
library(outbreaker2)
library(ape)
library(phangorn)
library(adephylo)
library(adegenet)
library(DECIPHER)
# session info -----
run_date <- date()
run_date
sessionInfo()
# setting working directory and other user preferences -----
if (interactive()) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
base_path <- find_root('base_environment.R')
setwd(base_path)
source('base_environment.R')
# preserve graphics settings ----
par_old <- par()
# load sequence data (in FASTA format)
fas <- "./R_example/sequences_from_session_1.fna"
dna <- readDNAStringSet(fas)
dna # the unaligned sequences
#
DNA <- AlignSeqs(dna)
DNA
# write alignments to file.
writeXStringSet(DNA, file="./R_example/sequences_from_session_1_aligned.fna")
# reload from file (not necessary but worth checking that write worked)
seqs <- read.dna("./R_example/sequences_from_session_1_aligned.fna", format="fasta")
seqs
#create a phyDat object
virus_phyDat <- phyDat(seqs, type = "DNA", levels = NULL)
tree <- NJ(dist.ml(virus_phyDat, "JC"))
# test a vareity of nucleotide substitution models
mt <- modelTest(virus_phyDat, tree = tree, model = c("JC", "F81"))
print(mt)
# choose a model and create a distance matrix
dna_dist <- dist.ml(virus_phyDat, model="JC69")
dna_dist
virus_UPGMA <- upgma(dna_dist)
virus_NJ <- NJ(dna_dist)
#CairoPDF(file = "test.pdf")
plot(virus_UPGMA, main="UPGMA")
#dev.off()
plot(virus_NJ, main = "Neighbor Joining")
plot(virus_NJ, type = "unrooted", cex = 0.5)
plot(virus_NJ, type = "cladogram")
plot(virus_NJ, type = "fan")
plot(virus_NJ, type = "radial")
bullseye(virus_NJ, font = 2, cex = 0.5)
# genome length alignment ----
# load dataset with five 100k+ BP DNA sequences
long_seqs <- readDNAStringSet(file.path(getwd(), "R_example", "plastid_genomes.fa"))
long_seqs
# prep as a local database ----
Seqs2DB(long_seqs, "XStringSet", "long_db", names(long_seqs))
# find synteny
synteny <- FindSynteny("long_db")
pairs(synteny)
plot(synteny)
# do alignment
alignment <- AlignSynteny(synteny, "long_db")
# Extract each alignment and Write FASTA Alignment files.
# DOne one by one. UNless you want to write more efficeint.
blocks <- unlist(alignment[[1]])
writeXStringSet(blocks, "genome_blocks_out.fa")
# outbreaker2 demo ----
# restore graphics settings
par(par_old)
fake_outbreak
str(fake_outbreak)
plot(fake_outbreak$w, type = "h", xlim = c(0, 5),
lwd = 30, col = "red", lend = 2,
xlab = "Days after infection",
ylab = "p(new case)",
main = "Generation time distribution")
args(outbreaker)
dna <- fake_outbreak$dna
dates <- fake_outbreak$sample
ctd <- fake_outbreak$ctd
w <- fake_outbreak$w
# lets just pretend this is real DNA data
write.dna(dna, "outbreaker_unaligned.fasta", format = "fasta")
fas <- "outbreaker_unaligned.fasta"
dna_2 <- readDNAStringSet(fas)
dna_2 # the unaligned sequences
#
DNA <- AlignSeqs(dna_2)
DNA
writeXStringSet(DNA, file="./R_example/outbreaker_aligned.fna")
seqs <- read.dna("./R_example/outbreaker_aligned.fna", format="fasta")
seqs
outbreaker_phyDat <- phyDat(seqs, type = "DNA", levels = NULL)
tree <- NJ(dist.ml(outbreaker_phyDat, "JC"))
mt <- modelTest(outbreaker_phyDat, tree= tree, model = c("JC", "F81"))
print(mt)
# choose a model and create a distance matrix
dna_dist <- dist.ml(outbreaker_phyDat, model="F81")
dna_dist
# contruct tree from matix
outbreaker_UPGMA<- upgma(dna_dist)
plot(outbreaker_UPGMA, main="UPGMA", "unrooted")
plot(outbreaker_UPGMA, main="UPGMA")
bullseye(outbreaker_UPGMA, font = 2, tip.color = any2col(dates, col.pal=seasun)$col)
# contruct the outbreaker model data set
data <- outbreaker_data(dna = dna, dates = dates, ctd = ctd, w_dens = w)
## we set the seed to ensure results won't change
set.seed(1)
# run the analysis with defaults
res <- outbreaker(data = data)
class(res)
dim(res)
names(res)
plot(res)
plot(res, "mu")
plot(res, "mu", "density", burnin = 2000)
plot(res, type = "alpha", burnin = 2000)
plot(res, type = "t_inf", burnin = 2000)
plot(res, type = "kappa", burnin = 2000)
plot(res, type = "network", burnin = 2000, min_support = 0.01, labels = data$ids)
